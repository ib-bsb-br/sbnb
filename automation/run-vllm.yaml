---

- hosts: "{{ lookup('ansible.builtin.env', 'SBNB_HOSTS') }}"
  gather_facts: false
  ignore_unreachable: true

  tasks:
    - name: Start vLLM container
      docker_container:
        name: vllm
        image: vllm/vllm-openai
        runtime: nvidia
        ipc_mode: host
        env:
          HUGGING_FACE_HUB_TOKEN: "{{ lookup('ansible.builtin.env', 'HUGGING_FACE_HUB_TOKEN') }}"
          CUDA_DEVICE_ORDER: PCI_BUS_ID
        ports:
          - 8000:8000
        volumes:
          - /mnt/sbnb-data/huggingface:/root/.cache/huggingface
        device_requests:
          - driver: nvidia
            count: -1 # this means we want all
            capabilities:
              - ['gpu','nvidia']
        command: > 
          --max-model-len 2048
          --gpu-memory-utilization 0.9
          --tensor-parallel-size 2
          --max-num-seqs 32
          --enforce-eager
          --model "allenai/OLMo-1B-hf"
